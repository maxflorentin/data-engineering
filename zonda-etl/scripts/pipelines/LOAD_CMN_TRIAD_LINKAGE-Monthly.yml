name: LOAD_CMN_TRIAD_LINKAGE-Monthly
description: 'Load Data from the linkage to Common Table'
owner: BI-Corp
active: true
#schedule_interval: '0 9 * * 6'
start_date: '2020-11-12'
#end_date: '2020-10-31'
catchup: false
retries: 1
retry_delay: 30
include_dummy_task: true
max_active_runs: 1
input:
  - name: date_from
    description: 'Date From in format YYYY-MM-DD'
tasks:
  - name: COMMON_LoadTable_bt_rcp_triadlinkage
    operator: ZondaHiveOperator
    config:
      connection_id: cloudera_hive_beeline
      schema: default
      is_hql_file: true
      hql:
        - '$ZONDA_DIR/repositories/zonda-etl/scripts/layers/common/recuperaciones/bt_rcp_triadlinkage/DDLT-Create_bt_rcp_triadlinkage.hql'
        - '$ZONDA_DIR/repositories/zonda-etl/scripts/layers/common/recuperaciones/bt_rcp_triadlinkage/ETL-Load_bt_rcp_triadlinkage.hql'
  - name: SHERIFF_Control
    operator: SparkSubmitOperator
    config:
      name: SHERIFF_Control
      connection_id: cloudera_spark2
      executor_cores: 5
      executor_memory: 8G
      num_executors: 5
      files: ['$ZONDA_DIR/repositories/zonda-etl/scripts/layers/common/recuperaciones/bt_rcp_triadlinkage/bt_rcp_triadlinkage_sheriff.json']
      application: '$ZONDA_DIR/repositories/zonda-etl/scripts/shared/sheriff/sheriff.py'
      conf: {
        'spark.yarn.appMasterEnv.partition_date': "{{ ti.xcom_pull(task_ids='InputConfig', key='partition_date', dag_id='LOAD_CMN_TRIAD_LINKAGE-Monthly') }}",
        'spark.yarn.appMasterEnv.KAFKA_BROKERS': "$KAFKA_BROKERS",
        'spark.yarn.appMasterEnv.QA_KAFKA_TOPIC': "$QA_KAFKA_TOPIC"
      }
      application_args: ['bt_rcp_triadlinkage_sheriff.json']
dependencies:
  COMMON_LoadTable_bt_rcp_triadlinkage: SHERIFF_Control
notifications:
  on_error: true
  channels: [$DEFAULT_SLACK_CHANNEL]
  users: [nbucardo@santandertecnologia.com.ar]