name: LOAD_STG_DATOS_GOB-Daily
description: 'Download Data of UVA From DATOS GOB BCRA'
owner: BI-Corp
active: true
start_date: '2020-07-31'
#schedule_interval: '0 6 * * *'
#catchup: true
retries: 3
retry_delay: 30
include_dummy_task: true
max_active_runs: 1
input:
  - name: date_from
    description: 'Date From in format YYYY-MM-DD'
  - name: date_to
    description: 'Date To in format YYYY-MM-DD'
  - name: shift
    description: 'Shift in days'
    default: 0
  - name: mode
    description: 'Partition level'
    default: days
tasks:

  - name: STAGING_uva_Parquetize
    operator: SparkSubmitOperator
    config:
      name: STAGING_uva_Parquetize
      connection_id: cloudera_spark2
      executor_cores: 5
      executor_memory: 8G
      num_executors: 2
      jars: '/aplicaciones/bi/zonda/repositories/guyra/jars/spark-cobol-0.5.6.jar,/aplicaciones/bi/zonda/repositories/guyra/jars/cobol-parser-0.5.6.jar,/aplicaciones/bi/zonda/repositories/guyra/jars/scodec-core_2.11-1.10.3.jar'
      files: ['$ZONDA_DIR/repositories/zonda-etl/scripts/layers/staging/datos_gob/uva/datos_gob_uva_schema.json']
      application: '$ZONDA_DIR/repositories/guyra/src/guyra.py'
      py_files: '$ZONDA_DIR/repositories/guyra/src/config_file.py'
      conf: {
        'spark.yarn.appMasterEnv.partition_date_filter': "{{ ti.xcom_pull(task_ids='InputConfig', key='partition_date', dag_id='LOAD_STG_DATOS_GOB-Daily') }}",
        'spark.yarn.appMasterEnv.file_date_filter': "{{ ti.xcom_pull(task_ids='InputConfig', key='partition_date_filter', dag_id='LOAD_STG_DATOS_GOB-Daily') }}",
        'spark.sql.sources.partitionOverwriteMode':'dynamic'
      }
      application_args: ['datos_gob_uva_schema.json']
#  - name: STAGING_DATOS_GOB_UVA_AddPartition
#    operator: ZondaHiveOperator
#    config:
#      connection_id: cloudera_hive_beeline
#      schema: default
#      is_hql_file: true
#      hql:
#        - '$ZONDA_DIR/repositories/zonda-etl/scripts/layers/staging/datos_gob/uva/DDLT-Create_Staging_Table.hql'
#        - '$ZONDA_DIR/repositories/zonda-etl/scripts/layers/staging/datos_gob/uva/ETLV-Alter_Partitions.hql'

  - name: STAGING_emae_actividades_Parquetize
    operator: SparkSubmitOperator
    config:
      name: STAGING_emae_actividades_Parquetize
      connection_id: cloudera_spark2
      executor_cores: 5
      executor_memory: 8G
      num_executors: 2
      jars: '/aplicaciones/bi/zonda/repositories/guyra/jars/spark-cobol-0.5.6.jar,/aplicaciones/bi/zonda/repositories/guyra/jars/cobol-parser-0.5.6.jar,/aplicaciones/bi/zonda/repositories/guyra/jars/scodec-core_2.11-1.10.3.jar'
      files: ['$ZONDA_DIR/repositories/zonda-etl/scripts/layers/staging/datos_gob/emae_actividades/datos_gob_emae_actividades_schema.json']
      application: '$ZONDA_DIR/repositories/guyra/src/guyra.py'
      py_files: '$ZONDA_DIR/repositories/guyra/src/config_file.py'
      conf: {
        'spark.yarn.appMasterEnv.partition_date_filter': "{{ ti.xcom_pull(task_ids='InputConfig', key='partition_date', dag_id='LOAD_STG_DATOS_GOB-Daily') }}",
        'spark.yarn.appMasterEnv.file_date_filter': "{{ ti.xcom_pull(task_ids='InputConfig', key='partition_date_filter', dag_id='LOAD_STG_DATOS_GOB-Daily') }}",
        'spark.sql.sources.partitionOverwriteMode':'dynamic'
      }
      application_args: ['datos_gob_emae_actividades_schema.json']
#  - name: STAGING_DATOS_GOB_EMAE_ACTIVIDADES_AddPartition
#    operator: ZondaHiveOperator
#    config:
#      connection_id: cloudera_hive_beeline
#      schema: default
#      is_hql_file: true
#      hql:
#        - '$ZONDA_DIR/repositories/zonda-etl/scripts/layers/staging/datos_gob/emae_actividades/DDLT-Create_Staging_Table.hql'
#        - '$ZONDA_DIR/repositories/zonda-etl/scripts/layers/staging/datos_gob/emae_actividades/ETLV-Alter_Partitions.hql'


  - name: STAGING_emae_indicadores_Parquetize
    operator: SparkSubmitOperator
    config:
      name: STAGING_emae_indicadores_Parquetize
      connection_id: cloudera_spark2
      executor_cores: 5
      executor_memory: 8G
      num_executors: 2
      jars: '/aplicaciones/bi/zonda/repositories/guyra/jars/spark-cobol-0.5.6.jar,/aplicaciones/bi/zonda/repositories/guyra/jars/cobol-parser-0.5.6.jar,/aplicaciones/bi/zonda/repositories/guyra/jars/scodec-core_2.11-1.10.3.jar'
      files: ['$ZONDA_DIR/repositories/zonda-etl/scripts/layers/staging/datos_gob/emae_indicadores/datos_gob_emae_indicadores_schema.json']
      application: '$ZONDA_DIR/repositories/guyra/src/guyra.py'
      py_files: '$ZONDA_DIR/repositories/guyra/src/config_file.py'
      conf: {
        'spark.yarn.appMasterEnv.partition_date_filter': "{{ ti.xcom_pull(task_ids='InputConfig', key='partition_date', dag_id='LOAD_STG_DATOS_GOB-Daily') }}",
        'spark.yarn.appMasterEnv.file_date_filter': "{{ ti.xcom_pull(task_ids='InputConfig', key='partition_date_filter', dag_id='LOAD_STG_DATOS_GOB-Daily') }}",
        'spark.sql.sources.partitionOverwriteMode':'dynamic'
      }
      application_args: ['datos_gob_emae_indicadores_schema.json']
#  - name: STAGING_DATOS_GOB_EMAE_INDICADORES_AddPartition
#    operator: ZondaHiveOperator
#    config:
#      connection_id: cloudera_hive_beeline
#      schema: default
#      is_hql_file: true
#      hql:
#        - '$ZONDA_DIR/repositories/zonda-etl/scripts/layers/staging/datos_gob/emae_indicadores/DDLT-Create_Staging_Table.hql'
#        - '$ZONDA_DIR/repositories/zonda-etl/scripts/layers/staging/datos_gob/emae_indicadores/ETLV-Alter_Partitions.hql'


#dependencies:
#  STAGING_DATOS_GOB_UVA_Parquetize: STAGING_DATOS_GOB_UVA_AddPartition
#  STAGING_DATOS_GOB_EMAE_ACTIVIDADES_Parquetize: STAGING_DATOS_GOB_EMAE_ACTIVIDADES_AddPartition
#  STAGING_DATOS_GOB_EMAE_INDICADORES_Parquetize: STAGING_DATOS_GOB_EMAE_INDICADORES_AddPartition
notifications:
  on_error: true
  channels: [$DEFAULT_SLACK_CHANNEL]
  users: [mcaamano@santandertecnologia.com.ar, fscagnettibrusatori@santandertecnologia.com.ar]
